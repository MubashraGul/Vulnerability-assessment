from __future__ import absolute_import, division, print_function
import requests
import re
from bs4 import BeautifulSoup
from urllib.parse import urlparse
import tkinter as tk
from shared import target_url  # Ensure this is defined in your shared module

# ANSI escape sequences for terminal colors
G = '\033[92m'  # green
R = '\033[91m'  # red
W = '\033[0m'  # white (normal)
Y = '\033[93m'  # yellow
bannerblue = '\033[94m'

good = f"{G}[+]{W}"
bad = f"{R}[-]{W}"
info = f"{Y}[i]{W}"
que = f"{Y}[?]{W}"

def parsing_url(url):
    """Extracts the hostname from a URL."""
    parsed_uri = urlparse(url)
    domain = '{uri.netloc}'.format(uri=parsed_uri)
    return domain

def results(table):
    """Extracts DNS and MX record details from an HTML table."""
    res = []
    trs = table.findAll('tr')
    for tr in trs:
        tds = tr.findAll('td')
        if len(tds) < 3:
            continue  # Skip rows that do not have enough columns
        pattern_ip = r'([0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3})'
        try:
            ip = re.findall(pattern_ip, tds[1].text)[0]
            domain = str(tds[0]).split('<br/>')[0].split('>')[1]
            header = ' '.join(tds[0].text.replace('\n', '').split(' ')[1:])
            reverse_dns = tds[1].find('span', attrs={}).text if tds[1].find('span', attrs={}) else ''
            additional_info = tds[2].text
            country = tds[2].find('span', attrs={}).text if tds[2].find('span', attrs={}) else ''
            autonomous_system = additional_info.split(' ')[0] if additional_info else ''
            provider = ' '.join(additional_info.split(' ')[1:]) if additional_info else ''
            provider = provider.replace(country, '') if country else provider
            data = {
                'domain': domain,
                'ip': ip,
                'reverse_dns': reverse_dns,
                'as': autonomous_system,
                'provider': provider,
                'country': country,
                'header': header
            }
            res.append(data)
        except IndexError as e:
            print(f"{bad} IndexError processing table row: {e}")
        except Exception as e:
            print(f"{bad} Error processing table row: {e}")
    return res

def fetch_csrf_token(session, url):
    """Fetches CSRF token from the provided URL."""
    response = session.get(url)
    soup = BeautifulSoup(response.text, 'html.parser')
    try:
        csrf_token = soup.find('input', attrs={'name': 'csrfmiddlewaretoken'})['value']
        return csrf_token
    except Exception as e:
        raise ValueError(f"Failed to retrieve CSRF token: {e}")

def dnsdumper(url, result_text):
    """Main function to retrieve DNS and MX records from dnsdumpster.com."""
    domain = parsing_url(url)
    dnsdumpster_url =target_url
    session = requests.Session()

    try:
        csrf_token = fetch_csrf_token(session, dnsdumpster_url)
        result_text.insert(tk.END, f"{info} Retrieved token: {csrf_token}\n")
    except ValueError as e:
        result_text.insert(tk.END, f"{bad} {e}\n")
        return

    cookies = {'csrftoken': csrf_token}
    headers = {'Referer': dnsdumpster_url}
    data = {'csrfmiddlewaretoken': csrf_token, 'targetip': domain, 'user': 'free'}

    response = session.post(dnsdumpster_url, cookies=cookies, data=data, headers=headers)
    if response.status_code == 200:
        soup = BeautifulSoup(response.content, 'html.parser')
        tables = soup.findAll('table')

        if len(tables) >= 2:  # Ensure there are enough tables to process
            res = {
                'domain': domain,
                'dns_records': {
                    'dns': results(tables[0]),
                    'mx': results(tables[1])
                }
            }

            print_dns_results(res, result_text)
        else:
            result_text.insert(tk.END, f"{bad} Not enough tables found on the page.\n")
    else:
        result_text.insert(tk.END, f"{bad} Failed to retrieve DNS records.\n")

def print_dns_results(results, result_text):
    """Prints the retrieved DNS and MX records in a formatted manner."""
    result_text.insert(tk.END, f"{que} Search for DNS Servers\n")
    for entry in results['dns_records']['dns']:
        result_text.insert(tk.END, f"{good} Host: {entry['domain']} \n{good} IP: {entry['ip']} \n{good} AS: {entry['as']} \n{bannerblue}----------------{W}\n")

    result_text.insert(tk.END, f"{que} Search for MX Records\n")
    for entry in results['dns_records']['mx']:
        result_text.insert(tk.END, f"{good} Host: {entry['domain']} \n{good} IP: {entry['ip']} \n{good} AS: {entry['as']} \n{bannerblue}----------------{W}\n")

def start_scan(result_text):
    url = target_url
    result_text.delete(1.0, tk.END)  # Clear previous results
    dnsdumper(url, result_text)

# Assuming this function will be called from the main GUI script
def integrate_dns_dumper(result_text):
    start_scan(result_text)
